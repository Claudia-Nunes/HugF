#!/usr/bin/env python3
"""
Script de teste para demonstrar o funcionamento do RAG sem depender da API de infer√™ncia do Hugging Face.
Este script simula a funcionalidade completa do RAG usando apenas os componentes locais.
"""

import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# Configura√ß√µes
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

print("=== Teste do Sistema RAG ===")
print("Carregando modelo de embeddings...")

# Inicializar o modelo de embeddings
embedder = SentenceTransformer(EMBEDDING_MODEL)
dim = embedder.get_sentence_embedding_dimension()

# Criar √≠ndice FAISS
index = faiss.IndexFlatIP(dim)
documents = []

print(f"Modelo carregado. Dimens√£o dos embeddings: {dim}")
print()

# Fun√ß√£o para adicionar documentos
def add_document(text):
    vec = embedder.encode([text], convert_to_numpy=True, normalize_embeddings=True)
    index.add(vec)
    documents.append(text)
    print(f"‚úì Documento adicionado: '{text}'")

# Fun√ß√£o para buscar documentos similares
def search_documents(query, top_k=3):
    query_embedding = embedder.encode([query], convert_to_numpy=True, normalize_embeddings=True)
    distances, indices = index.search(query_embedding, top_k)
    
    results = []
    for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):
        if idx < len(documents):
            results.append({
                'document': documents[idx],
                'similarity': float(distance),
                'rank': i + 1
            })
    
    return results

# Adicionar documentos de exemplo
print("1. Adicionando documentos ao √≠ndice:")
add_document("A capital da Fran√ßa √© Paris.")
add_document("O Brasil √© o maior produtor de caf√© do mundo.")
add_document("Python √© uma linguagem de programa√ß√£o popular.")
add_document("O Rio de Janeiro √© conhecido pelo Cristo Redentor.")
add_document("Machine Learning √© um subcampo da intelig√™ncia artificial.")

print(f"\nTotal de documentos indexados: {index.ntotal}")
print()

# Testar consultas
queries = [
    "Qual √© a capital da Fran√ßa?",
    "Quem produz mais caf√©?",
    "O que √© Python?",
    "Pontos tur√≠sticos do Rio de Janeiro",
    "O que √© aprendizado de m√°quina?"
]

print("2. Testando consultas:")
for query in queries:
    print(f"\nüîç Pergunta: '{query}'")
    results = search_documents(query, top_k=2)
    
    if results:
        print("üìÑ Documentos mais relevantes:")
        for result in results:
            print(f"   {result['rank']}. (Similaridade: {result['similarity']:.3f}) {result['document']}")
        
        # Simular resposta baseada no contexto mais relevante
        best_context = results[0]['document']
        print(f"üí° Resposta baseada no contexto: {best_context}")
    else:
        print("‚ùå Nenhum documento relevante encontrado.")

print("\n=== Teste Conclu√≠do ===")
print("O sistema RAG est√° funcionando corretamente!")
print("- ‚úì Embeddings gerados com sucesso")
print("- ‚úì √çndice FAISS operacional") 
print("- ‚úì Busca por similaridade funcionando")
print("- ‚úì Recupera√ß√£o de contexto eficiente")
